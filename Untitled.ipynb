{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77a372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3118906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce74a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc0c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module):\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88b1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.Sigmoid(),\n",
    "            nn.LazyLinear(84), nn.Sigmoid(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    def forward(self, x):\n",
    "        modelOutput = self.net(x)\n",
    "        return modelOutput\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X = layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e96223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernLeNet(nn.Module):\n",
    "    def __init__(self, lr=0.001, num_classes=10):\n",
    "        super(ModernLeNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.ReLU(),\n",
    "            nn.LazyLinear(84), nn.ReLU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X=layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc0b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernLeNet2(nn.Module):\n",
    "    def __init__(self, lr=0.001, num_classes=10):\n",
    "        super(ModernLeNet2, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=2, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.ReLU(),\n",
    "            nn.LazyLinear(84), nn.ReLU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X=layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e40648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernLeNet3(nn.Module):\n",
    "    def __init__(self, lr=0.001, num_classes=10):\n",
    "        super(ModernLeNet3, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(12, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(24, kernel_size=5), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(180), nn.ReLU(),\n",
    "            nn.LazyLinear(108), nn.ReLU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X=layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8557de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernLeNet4(nn.Module):\n",
    "    def __init__(self, lr=0.001, num_classes=10):\n",
    "        super(ModernLeNet4, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5, padding=4), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(36, kernel_size=5), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.ReLU(),\n",
    "            nn.LazyLinear(84), nn.ReLU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X=layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3dff2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernLeNet5(nn.Module):\n",
    "    def __init__(self, lr=0.001, num_classes=10):\n",
    "        super(ModernLeNet5, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120), nn.ReLU(),\n",
    "            nn.LazyLinear(84), nn.ReLU(),\n",
    "            nn.LazyLinear(num_classes))\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    def layer_summary(self, X_shape):\n",
    "        X = torch.randn(*X_shape)\n",
    "        for layer in self.net:\n",
    "            X=layer(X)\n",
    "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69811a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape:\t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape:\t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape:\t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape:\t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 400])\n",
      "Linear output shape:\t torch.Size([1, 120])\n",
      "Sigmoid output shape:\t torch.Size([1, 120])\n",
      "Linear output shape:\t torch.Size([1, 84])\n",
      "Sigmoid output shape:\t torch.Size([1, 84])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "model.layer_summary((1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26afb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 6, 28, 28])\n",
      "ReLU output shape:\t torch.Size([1, 6, 28, 28])\n",
      "MaxPool2d output shape:\t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 16, 10, 10])\n",
      "ReLU output shape:\t torch.Size([1, 16, 10, 10])\n",
      "MaxPool2d output shape:\t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 400])\n",
      "Linear output shape:\t torch.Size([1, 120])\n",
      "ReLU output shape:\t torch.Size([1, 120])\n",
      "Linear output shape:\t torch.Size([1, 84])\n",
      "ReLU output shape:\t torch.Size([1, 84])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "modern_model = ModernLeNet()\n",
    "modern_model.layer_summary((1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00eaaa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 12, 28, 28])\n",
      "ReLU output shape:\t torch.Size([1, 12, 28, 28])\n",
      "MaxPool2d output shape:\t torch.Size([1, 12, 14, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 24, 10, 10])\n",
      "ReLU output shape:\t torch.Size([1, 24, 10, 10])\n",
      "MaxPool2d output shape:\t torch.Size([1, 24, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 600])\n",
      "Linear output shape:\t torch.Size([1, 180])\n",
      "ReLU output shape:\t torch.Size([1, 180])\n",
      "Linear output shape:\t torch.Size([1, 108])\n",
      "ReLU output shape:\t torch.Size([1, 108])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "improved_modern_model2 = ModernLeNet3()\n",
    "improved_modern_model2.layer_summary((1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b10f0551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 6, 28, 28])\n",
      "ReLU output shape:\t torch.Size([1, 6, 28, 28])\n",
      "MaxPool2d output shape:\t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 16, 18, 18])\n",
      "ReLU output shape:\t torch.Size([1, 16, 18, 18])\n",
      "MaxPool2d output shape:\t torch.Size([1, 16, 9, 9])\n",
      "Conv2d output shape:\t torch.Size([1, 36, 5, 5])\n",
      "ReLU output shape:\t torch.Size([1, 36, 5, 5])\n",
      "MaxPool2d output shape:\t torch.Size([1, 36, 2, 2])\n",
      "Flatten output shape:\t torch.Size([1, 144])\n",
      "Linear output shape:\t torch.Size([1, 120])\n",
      "ReLU output shape:\t torch.Size([1, 120])\n",
      "Linear output shape:\t torch.Size([1, 84])\n",
      "ReLU output shape:\t torch.Size([1, 84])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "improved_modern_model3 = ModernLeNet4()\n",
    "improved_modern_model3.layer_summary((1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7c863218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 16, 24, 24])\n",
      "ReLU output shape:\t torch.Size([1, 16, 24, 24])\n",
      "MaxPool2d output shape:\t torch.Size([1, 16, 12, 12])\n",
      "Flatten output shape:\t torch.Size([1, 2304])\n",
      "Linear output shape:\t torch.Size([1, 120])\n",
      "ReLU output shape:\t torch.Size([1, 120])\n",
      "Linear output shape:\t torch.Size([1, 84])\n",
      "ReLU output shape:\t torch.Size([1, 84])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "improved_modern_model4 = ModernLeNet5()\n",
    "improved_modern_model4.layer_summary((1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6c5a352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(root='./data',\n",
    "                                              train=True,\n",
    "                                              transform=transforms.ToTensor(),\n",
    "                                              download = True)\n",
    "val_data = torchvision.datasets.FashionMNIST(root='./data',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True, num_workers=os.cpu_count())\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data,\n",
    "                                        batch_size=100,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b41ae991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet().to(device)\n",
    "modern_model = ModernLeNet().to(device)\n",
    "improved_modern_model = ModernLeNet2().to(device)\n",
    "improved_modern_model2 = ModernLeNet3().to(device)\n",
    "improved_modern_model3 = ModernLeNet4().to(device)\n",
    "improved_modern_model4 = ModernLeNet5().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "98d165c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossCriterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optim2 = torch.optim.Adam(modern_model.parameters(), lr=0.001)\n",
    "optim3 = torch.optim.Adam(improved_modern_model.parameters(), lr=0.001)\n",
    "optim4 = torch.optim.Adam(improved_modern_model2.parameters(), lr=0.001)\n",
    "optim5 = torch.optim.Adam(improved_modern_model3.parameters(), lr=0.001)\n",
    "optim6 = torch.optim.Adam(improved_modern_model4.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "609b0920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGKCAYAAACsHiO8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9S0lEQVR4nO3df3BVdX7/8XdACElIAhFIiPwwSgBXVhAEFBHQLdnBKer6Y3a0Y113Z1bkR8vQKSMyHVPrgtop47SsrrYWrTMonQ4qu/4oWcXgLmtFxAVhRdEAQYgRCElIgPDjfP9wyHeTz+voucnNJ/dcno+Z/MGbc+/5nHvf9/Lm5H3eJyMIgsAAAAA86dHdCwAAAOcXig8AAOAVxQcAAPCK4gMAAHhF8QEAALyi+AAAAF5RfAAAAK8oPgAAgFcUHwAAwCuKDwAA4FWXFR9PPvmklZSUWJ8+fWzChAn27rvvdtWugKQidxFX5C7i4oKueNI1a9bYwoUL7cknn7Rrr73Wnn76aZs1a5bt3LnThg0b9q2PPXv2rB04cMByc3MtIyOjK5aH80AQBNbY2GjFxcXWo0f0GrszuWtG/qLzyF3EVUK5G3SBSZMmBXPmzGkTGz16dPDAAw9852Orq6sDM+OHn6T8VFdXe8td8pefZP6Qu/zE9SdK7ib9zEdLS4tt2bLFHnjggTbxsrIy27Rpk7P9yZMn7eTJk61/DrjJLpIoNzc38raJ5q7Z+ZG/ffv2dWITJkyQ21ZWViZ132PHjpXxY8eOObHPP/88qfvubuRu502fPt2JzZkzR267bds2J1ZYWOjEvvjiCyeWk5PjxPr16yf3c/r0aSd28cUXO7G/+qu/ko+Pgyi5m/Ti49ChQ3bmzBnnTSssLLSamhpn++XLl9s//uM/JnsZgJlZQqePE81ds/Mjf9VreMEFXfIbW0fPnj0TiqcTcjecem1U8aTyNDs7Wz5nnz59nFhWVpYTy8zM7PBjzcxOnToVeU1xFSV3u6zhtP3OgyCQC1qyZInV19e3/lRXV3fVkoBIouauGfmL1ELuIi6S/t+XAQMGWM+ePZ1qu7a2Vp7CyszMlJUk4FuiuWtG/iI1kLuIm6QXH71797YJEyZYRUWF/ehHP2qNV1RU2M0335zs3QFJk665q04Jm5ktXLjQid15551OrH///k5s4MCB8jmbm5udWEFBwXesMNyJEydk/Pjx407szJkzTkz1oPzHf/yHE3vzzTc7sLrUka65Gybqr13Ky8ud2NSpU+Vz3nTTTZH23dDQ4MTUr03CfjWpPiPq8X/5l3/pxH7zm99EWWIsdMkvbhctWmR33323XXXVVXbNNdfYM888Y/v27Qtt9AFSBbmLuCJ3ESddUnz8+Mc/tsOHD9vDDz9sBw8etDFjxtjrr79uw4cP74rdAUlD7iKuyF3ESZe1rM+dO9fmzp3bVU8PdBlyF3FF7iIuuLcLAADwys/F+gC8eOyxx5zYz3/+c7mtGgSkGjlV7MiRI/I51WwDNRBMzeloaWlxYqo5z8zk6GZ15YZq2lMNmH/4wx/kfqZNmybj6F5nz56NtN24ceOcWFjuHjp0yIlFbSQ9fPiwE1PDxMx0s+yIESOc2OjRo51YOjWccuYDAAB4RfEBAAC8ovgAAABeUXwAAACvKD4AAIBXXO0CxJS6imXx4sVOLOyupuoqlKh69+4t42ocuoqpUdjqCoZevXpFXpPajzpGNYZ9ypQp8jl//etfO7HZs2dHXhO6V9++fZ2YuqrFzCwvL8+JqauqTp486cTU1Vth981Rj1eGDh0aabu44swHAADwiuIDAAB4RfEBAAC8ovgAAABe0XAKxNQ//dM/ObGGhgYnFjaKWo2JLioqirTvuro6GVf7UmOmc3JynFifPn2cmBpbbaYb/FQjqWr6U+Otv/rqK7kfNV59wIABTiysiRH+FBYWRtru1KlTMq6aoFXDqco9leNhnzu1H/W5HTRokHx8uuDMBwAA8IriAwAAeEXxAQAAvKL4AAAAXtFwCsRUfn6+E1PTE1XTnJluLn3yySed2DPPPOPEtmzZIp/z4MGDTmzIkCFOrLGx0Ynt27fPiYU13bW0tDixwYMHO7H9+/c7MfUaqemWZmZZWVlO7JJLLnFiNJx2vzFjxkTaLqzhVL3XqolZxcI+Y4pqWFU5qRqb0wlnPgAAgFcUHwAAwCuKDwAA4BXFBwAA8IqGUyCm1PROdVt5NdEzzIMPPujE6uvrnZhqmjMzy87OdmLvvPOOE7v++usjrWfnzp0yftlllzkx1TT6N3/zN07skUcecWJff/213I9qJLz22mud2Pvvvy8fD3+uuOIKJ6Yak9VnxEznrvqMqTw7cuRIlCWamf48qv00NTVFfs444swHAADwiuIDAAB4RfEBAAC8ovgAAABe0XCKb6UaC9WtotVtosOo5io14W/EiBHy8bt37468r3TRu3fvSNup90a93mH+67/+y4ndfPPNkR9fUFDgxFRz6cMPP+zE1G3F77zzzsj7GTZsmBNbs2aNE1MNp2ETKtU0yyuvvFJui+41adIkJ6Y+D6qx1Mzs9OnTTkxNEf7www+d2Lhx45xYXV2d3I/6rlNrqq6ulo9PF5z5AAAAXlF8AAAAryg+AACAVxQfAADAK4oPAADgFVe7xIAax6tiqrP7oosuks95zTXXOLE33njDiXXFiF/V7a3cdtttMv7YY48lczmxUFxcHGk7lQNZWVmR9xOWL1HdcccdkbZTV9WosddhY9z/+Mc/OrHBgwc7sWPHjkVaTyJKS0uT/pzoPDVy/9SpU05MfUbMzPr27evEDh486MSuvvpqJ6au9gu7gkrFL7jA/ac4kZHtccSZDwAA4BXFBwAA8IriAwAAeEXxAQAAvKLhNKbCmqbau+6662R88uTJTkw1Nf7rv/5rYguLYNCgQU7shz/8oRNT47bPVwMGDOjwY3v16iXjqhlPNZyGNc4plZWVkbb73//9Xyd2ySWXOLHDhw/Lx994441ObMOGDU5MNaaqJtSwY1Qjt4uKiuS26F5qFLp6/xJpOF27dm2H1xPWLK1G9itRb6kQV5z5AAAAXlF8AAAArxIuPjZu3GizZ8+24uJiy8jIsFdeeaXN3wdBYOXl5VZcXGxZWVk2Y8YM27FjR7LWC3QYuYu4IneRbhIuPpqammzs2LG2cuVK+fePP/64rVixwlauXGmbN2+2oqIimzlzpjU2NnZ6sUBnkLuIK3IX6SbhhtNZs2bZrFmz5N8FQWBPPPGELV261G699VYzM3v++eetsLDQVq9ebffdd1/nVnueUo1LqpHqqquucmJq6p+Z2VdffeXE1OTGl19+2YmpyXthUzT37t3rxC688EInlpeX58T2798vn7Oj4py7Q4YMibSdmnwbprm52YmpZkrVoBe2n1GjRjmxRx991IldeumlUZZof/rTn2R89OjRTmz48OFObO7cuU5MTfcNmybZ0tLixDo7BbYj4py7vqhGdpXjahppmBdffDHSdmpqc0FBgdw2rIm6vezs7EjbxVVSez6qqqqspqbGysrKWmOZmZk2ffp027RpUzJ3BSQVuYu4IncRR0m91LampsbMzAoLC9vECwsL5f+Azb6pGP+8auTySnSHjuSuGfmL7kfuIo665GqX9qdkgyAIPU27fPlyy8/Pb/0ZOnRoVywJiCSR3DUjf5E6yF3ESVKLj3O/Lz5XiZ9TW1vrVOXnLFmyxOrr61t/qqurk7kkIJKO5K4Z+YvuR+4ijpL6a5eSkhIrKiqyiooKu/LKK83sm4atysrK0NugZ2ZmWmZmZjKXEWtq0qJqLs3JyXFi6nbmYbev79OnjxPLzc11Yup/TmqNYf/Duvzyy52Y+pKrq6tzYuo2012lI7lr5i9/Bw4cGGk71RwaNmlRxdX0z1/84hdOLGxq6p/3HZwzduxYJzZmzBgnpvJPNZaa6SbWNWvWOLFx48bJx7cX9hqp1zPs2LtLqueuL6pBU+VzIt8ramqu8oc//MGJqcZms/Bcay9qY2pcJfztfuzYMdu9e3frn6uqquyjjz6ygoICGzZsmC1cuNCWLVtmpaWlVlpaasuWLbPs7Gy76667krpwIFHkLuKK3EW6Sbj4+OCDD+z6669v/fOiRYvMzOyee+6x5557zhYvXmzHjx+3uXPnWl1dnU2ePNnWr18v/1cD+ETuIq7IXaSbhIuPGTNmfOt10hkZGVZeXm7l5eWdWReQdOQu4orcRbrh3i4AAMArig8AAOCVv8sJYkJdtRF2ulNd9aG2VbGwjuczZ8581xLNzGzOnDlOrP2ldmZmJ06ckI+/+OKLnZi6AkaNYVdrV1cFmH1zT4r21MhqNV49rBNfXemj9pNOBg8eHGk79T6oPDXTV23U19c7sQcffDDSvsMer3Loe9/7XqTnUzltpq/+Ccv19hL5PIbldZTHR/0sw6+wq5XUVYVhVwu2t2fPHic2depUuW3UWyCoz1I64cwHAADwiuIDAAB4RfEBAAC8ovgAAABenTcNp1EbSb/tWvr2fDWj3XnnnU7s3P0c/tyHH37oxMKaq/r16+fE1DjfI0eOOLEBAwY4sbBhRlFHCaumSDUu2cystLTUiX300UeR9hNXUcerK6rB18zsrbfecmLTpk1zYvv373diYfnbu3dvJ6bGWTc2NsrHtxeWv6oRVTVMq/2oRr6wMexRR1yrBu7PP/880mPRddT3eVhOdeb9Up+RsEbvRP6NSWec+QAAAF5RfAAAAK8oPgAAgFcUHwAAwKvzpuE0apOPahIKaxxSTXdqP4k0l957771ObNSoUU6surraialG0LBpellZWU7syy+/dGKqkVQ12jY3N8v9qCbARKbIKj/84Q+dWLo3nKoGYaVv375OTDXDmZk9//zzTuzGG290YmHvraI+K+r9Vk2oSlheqKZBNRFXTa1ctWqVEwtrOI1KffZoOO1+p06dcmJqQrKZ2ccff9zh/bz22mtObPHixXLbsH9Pzje8CgAAwCuKDwAA4BXFBwAA8IriAwAAeBXrhtNEGndU45pqhFPNlFEnmYYpLi52YrfeeqvcVjWCfvbZZ05MNRaqhrsLL7xQ7kdNvVSvUdiU0fbCmmrVLanVtk1NTU4s7HW/9tprI60pnRQUFDixqO/X119/LZ+zrq4u0r5VroRNiUz29Maw51OTc9W2auLq//3f/3Vq/8ePH3diUW+TDr+iTlg2M6uqqurwfrZt2+bEVO6ZhX922lPfiemEMx8AAMArig8AAOAVxQcAAPCK4gMAAHiVsg2nPXr0aNPEpZoUO9sIGrU5Lux25sOHD3dio0ePdmKDBw92YmG3OW9oaHBiarplXl6eE4s69dFMv3bqeNRzHj161ImpSYJh+1GNwqqJL6xZTN0m/fLLL2/z5zNnztgnn3wiHx9HKgdUM6+aKHvs2DH5nJdddlmkfavPXlgzndKZJtSwRk71nCqmXrdE1qP2r/I37DsC/qhJvqoBO+z9P3DgQIf3rSbphonaBEvDKQAAQBJRfAAAAK8oPgAAgFcUHwAAwCuKDwAA4FXKXu0S5UqWwsJCGVdXbeTk5ESKqfHmJSUlcj+qk1pd9aGuNggbDZ+fnx9pTaq7Wq2nublZ7kddKaGuYDh48GCkNYaNYVcjvNVo+P79+zuxsG7voqIiJ9Z+jHwi3edxEHWcuLJr1y4Zv/TSSyM9Xu0nLH+j3sYgqkTGq6ucVrlaW1sbef9qP+p4BgwYEPk50TW++uorJ6ZyPOxqk5EjR3Z432FXLypht6JoL+qtLeKKMx8AAMArig8AAOAVxQcAAPCK4gMAAHiVsg2n7f3FX/yFEysuLpbbqqbPQYMGOTHVNKcaXcNGh6sx36qZUjVIhjXhqXHoqmlTrV3tO6y5SjVzquOpr693Yuq1TIQ6HvW6q0ZbM90Y277BNN0aTi+4wP2oRm1c+/TTT2V82rRpHd53GJXXKha1WTbsc6LyP+p7rsZwq5iZ28gcJjc3N9J26DqbN292YuoWAqox2cxs7NixSV+TEnbLi/bC1pkuOPMBAAC8ovgAAABeUXwAAACvKD4AAIBXKdtwesMNN7RpdPvZz37mbPPJJ5/Ix6qpnA0NDU5MNWOqSXVhTZuKatpUDZJhzYJ5eXlOTDXdqWZM1bTZq1cvuR/VBKsmxl5++eWRnjOR10g1u6ppfidOnIj8+PZTK6NMyI2T48ePO7GoDadhr8Xo0aOdmGquDptmmmxqP2GNqeqYor4eI0aMcGI1NTVyW/U5Ud8R6T6NMg42btzoxO69914nFnYBwfjx45O6nrB8jPpdGTWf44ozHwAAwCuKDwAA4FVCxcfy5ctt4sSJlpuba4MGDbJbbrnFuWlVEARWXl5uxcXFlpWVZTNmzLAdO3YkddFAoshdxBW5i3SUUPFRWVlp8+bNs/fee88qKirs9OnTVlZW1uZ38I8//ritWLHCVq5caZs3b7aioiKbOXOm7IUAfCF3EVfkLtJRQg2nb775Zps/r1q1ygYNGmRbtmyxadOmWRAE9sQTT9jSpUvt1ltvNTOz559/3goLC2316tV23333Rd7Xli1b2jRaXn311c423//+9+Vjr7322kj7UBMR1Yf1yJEj8vEqriaCqobTsMmNaqLiqFGjnJhqcFPNqmENe2qa37Zt25zYnj17nJiaNhs2tS/qJEv1Xnz55ZdyW9U83H66a/tmLZ+52xVU81nUxrWwCaUq15qbmzu8n0REzYswquE06jpvvvlmJ6by3MzsyiuvjLTv/v37R9p3R8Q9d33ZtGmTE1NN62GTcNs3rXdWWOEX9t3fXld87lJJp3o+zv1DW1BQYGZmVVVVVlNTY2VlZa3bZGZm2vTp02ViAN2F3EVckbtIBx2+1DYIAlu0aJFNnTrVxowZY2b//3K19pdsFhYW2t69e+XznDx5ss0Me/W/WiCZkpW7ZuQv/CJ3kS46fOZj/vz5tm3bNnvxxRedv2t/WikIgtBTTcuXL7f8/PzWn6FDh3Z0SUAkycpdM/IXfpG7SBcdKj4WLFhg69atsw0bNtiQIUNa4+cG8rQf2FNbWysHWJmZLVmyxOrr61t/qqurO7IkIJJk5q4Z+Qt/yF2kk4R+7RIEgS1YsMBefvlle+edd6ykpKTN35eUlFhRUZFVVFS0Nmq1tLRYZWWlPfbYY/I5MzMzZbNi+8bNhx9+OPI61a3lJ0+e7MRGjhzpxKZMmeLELr74YrmfK664wonl5OQ4sURuKa6a2VRj6/bt251YRUWFE3vjjTfkfsKmh0axbt06JzZs2DC57aFDh5yYasRSsbDGMHWr6c8++6zNn9u/vl2Ru2bh+ZtsquG0T58+kR6rbituphuh1WurGlbDpqZGbaZT2yXyOVGiNuipz7NqtjYzu/322yM9Z9gk4WSIe+76on7FpH6VFHbM6vN0ySWXOLEvvvgi0nrCJqmGNYC3l+4NpwkVH/PmzbPVq1fbq6++arm5ua2Vdn5+vmVlZVlGRoYtXLjQli1bZqWlpVZaWmrLli2z7Oxsu+uuu7rkAIAoyF3EFbmLdJRQ8fHUU0+ZmdmMGTPaxFetWmU/+clPzMxs8eLFdvz4cZs7d67V1dXZ5MmTbf369Zabm5uUBQMdQe4irshdpKOEf+3yXTIyMqy8vNzKy8s7uiYg6chdxBW5i3TEvV0AAIBXFB8AAMCrDg8ZS2XHjh1zYm+99Vak2LnfryLcTTfd1N1LOO+0tLQ4sahXloSN/s7Kyoq0n7ArW5So26pfJUSNmUW/Wkbd7uCaa65xYp9++qncj6LWpF5LdD91ZUvYVSTq6q/OXO1y8OBBGVdXW6krGnv0SO9zA+l9dAAAIOVQfAAAAK8oPgAAgFcUHwAAwKu0bDgF0o0a1Xz8+HEnpm4t8C//8i/yOX/wgx84MdU4qUa7JyJqI2nUBloz3TSo1pmXl+fE3nnnHSf2m9/8Ru7noYceirQf1ayIrhN1FP/LL7/sxMKmvqoGz6lTpzqx3/72t1GWaE1NTZG2M9PHc/To0ciPjyPOfAAAAK8oPgAAgFcUHwAAwCuKDwAA4BUNp0AMZGdnOzHV+KgaU8OaIQ8dOuTESktLndjnn3/uxDo7fTFqc2nYdmqS6unTp51YQUGBE6utrXVi6rUIo1734cOHR348Oi9qw+mrr77qxP76r/9aPqf67Nx2221OLOrN+y64QP/zGrUB+8SJE5H2E1ec+QAAAF5RfAAAAK8oPgAAgFcUHwAAwCsaToEY2LRpkxNTt4ZXTWpht4sfOXJk5xeWJtSt083MGhsbnZi6TfvmzZuTviaEUw3Pqgn5jTfecGJ1dXXyOdX7qp4zqo8//ljGv//97zsxNa24uLi4w/uOA858AAAAryg+AACAVxQfAADAK4oPAADgFcUHAADwiqtdgBh4//33nZgaud7S0uLEOtOxf77o1auXjKsrINS4+mPHjiV9TQinRtxHtW/fPhm/+uqrnVhOTo4TmzJlihNTV6P17NlT7qdPnz5OTOXfgAED5OPTBWc+AACAVxQfAADAK4oPAADgFcUHAADwioZTIAb279/vxD788EMnpsarNzU1Rd7PBRe4XwmquS8jIyPyc3YntU51PLt375aPf+2115xYfn6+E3vvvfc6sDp0VBAEHX7sM888I+OffPKJE3vppZecmGouVV544QUZV/mjxvi/++67kfYTV5z5AAAAXlF8AAAAryg+AACAVynX89GZ3+UB7fnOp67an+pTUIOtTp482ak1qW3Ph89k2DE2Nzc7MdUXc/r0aW9r6irnw/tspgfxmenb2nfmfQ17rMqpZO+7u0XJpYwgxTJu//79NnTo0O5eBtJEdXW1DRkyxNv+yF8kC7mLuIqSuylXfJw9e9YOHDhgubm51tjYaEOHDrXq6mrLy8vr7qV1WkNDA8fjSRAE1tjYaMXFxdajh7/fLp7L3yAIbNiwYSn52nREKr/XHZHKx0PuJlcqv9cdkcrHk0juptyvXXr06NFaMZ27TC4vLy/lXuTO4Hj8UJe0dbVz+dvQ0GBmqfvadBTH4we5m3wcjx9Rc5eGUwAA4BXFBwAA8Cqli4/MzEx76KGH5G2t44jjOX+k22vD8Zw/0u214XhSU8o1nAIAgPSW0mc+AABA+qH4AAAAXlF8AAAAr1K6+HjyySetpKTE+vTpYxMmTIjNLYY3btxos2fPtuLiYsvIyLBXXnmlzd8HQWDl5eVWXFxsWVlZNmPGDNuxY0f3LPY7LF++3CZOnGi5ubk2aNAgu+WWW2zXrl1ttonT8fhC7nY/crdjyN3UkO75m7LFx5o1a2zhwoW2dOlS27p1q1133XU2a9Ys27dvX3cv7Ts1NTXZ2LFjbeXKlfLvH3/8cVuxYoWtXLnSNm/ebEVFRTZz5kxrbGz0vNLvVllZafPmzbP33nvPKioq7PTp01ZWVmZNTU2t28TpeHwgd1MDuZs4cjd1pH3+Bilq0qRJwZw5c9rERo8eHTzwwAPdtKKOMbPg5Zdfbv3z2bNng6KiouDRRx9tjZ04cSLIz88PfvWrX3XDChNTW1sbmFlQWVkZBEH8j6crkLupidz9buRu6kq3/E3JMx8tLS22ZcsWKysraxMvKyuzTZs2ddOqkqOqqspqamraHFtmZqZNnz49FsdWX19vZmYFBQVmFv/jSTZyN3WRu9+O3E1t6Za/KVl8HDp0yM6cOWOFhYVt4oWFhVZTU9NNq0qOc+uP47EFQWCLFi2yqVOn2pgxY8ws3sfTFcjd1ETufjdyN3WlY/6m3I3l/ty5G8udEwSBE4urOB7b/Pnzbdu2bfa73/3O+bs4Hk9XSufXI47HRu5Gl86vR1yPLR3zNyXPfAwYMMB69uzpVG+1tbVOlRc3RUVFZmaxO7YFCxbYunXrbMOGDa13HTaL7/F0FXI39ZC70ZC7qSld8zcli4/evXvbhAkTrKKiok28oqLCpkyZ0k2rSo6SkhIrKipqc2wtLS1WWVmZkscWBIHNnz/f1q5da2+//baVlJS0+fu4HU9XI3dTB7mbGHI3taR9/nZDk2skL730UtCrV6/g2WefDXbu3BksXLgwyMnJCfbs2dPdS/tOjY2NwdatW4OtW7cGZhasWLEi2Lp1a7B3794gCILg0UcfDfLz84O1a9cG27dvD+68885g8ODBQUNDQzev3HX//fcH+fn5wTvvvBMcPHiw9ae5ubl1mzgdjw/kbmogdxNH7qaOdM/flC0+giAIfvnLXwbDhw8PevfuHYwfP771EqNUt2HDhsDMnJ977rknCIJvLpF66KGHgqKioiAzMzOYNm1asH379u5ddAh1HGYWrFq1qnWbOB2PL+Ru9yN3O4bcTQ3pnr/c1RYAAHiVkj0fAAAgfVF8AAAAryg+AACAVxQfAADAK4oPAADgFcUHAADwiuIDAAB4RfEBAAC8ovgAAABeUXwAAACvKD4AAIBXFB8AAMArig8AAOAVxQcAAPCK4gMAAHhF8QEAALyi+AAAAF5RfAAAAK8oPgAAgFcUHwAAwCuKDwAA4BXFBwAA8IriAwAAeEXxAQAAvKL4AAAAXlF8AAAAryg+AACAVxQfAADAK4oPAADgFcUHAADwiuIDAAB4RfEBAAC8ovgAAABeXdBVT/zkk0/aP//zP9vBgwft8ssvtyeeeMKuu+6673zc2bNn7cCBA5abm2sZGRldtTykuSAIrLGx0YqLi61Hj8Rq7I7mrhn5i84jdxFXCeVu0AVeeumloFevXsG///u/Bzt37gz+9m//NsjJyQn27t37nY+trq4OzIwffpLyU11d7S13yV9+kvlD7vIT158ouZsRBEFgSTZ58mQbP368PfXUU62xyy67zG655RZbvnz5tz62vr7e+vXrl+wleXPhhRc6sXvvvdeJNTQ0yMcfP3480n7U49Vb2bNnT/n4Xr16ObFDhw45sXfffdeJnTp1KsoSU8LRo0ctPz8/8vadyV2z5OSv+l9nF3xMO+Wqq66S8ZycHCemci0sL9vLzMyUcZWrmzZtivSccRHH3E01r732mhM7ffq03LalpcWJqfzbt29fpO0GDRok99PU1OTE1OdBnTm444475HOmmii5m/Rfu7S0tNiWLVvsgQceaBMvKyuTXw4nT560kydPtv65sbEx2UvySiWMSszevXvLx585cybSftQXeiLFh9r/BRe46RD306+JrD/R3DXrmvyNWnxEPbauKFxUroTFO1N8qMd+2/7TSRxzN9WoYjis+FA51adPHyeWlZUVaTu1b7Po39OJ/sotlUTJ3aQf3aFDh+zMmTNWWFjYJl5YWGg1NTXO9suXL7f8/PzWn6FDhyZ7SUAkieauGfmL1EDuIm66rLRqX/kEQSCroSVLllh9fX3rT3V1dVctCYgkau6akb9ILeQu4iLp5y4HDBhgPXv2dKrt2tpapyo3++ZXEmG/142j22+/3Yn9wz/8gxM7cuSIfPzBgwed2CWXXOLE9u/f78Q+++wzJ3bZZZfJ/Zw4ccKJ/fa3v3Vi6j174YUX5HPGXaK5a9Y1+evrVyy5ublO7IYbbnBi48ePd2KzZs2Sz7lr165Ia+rbt68TU/1SqrfDTJ/6Xrp0qRP79a9/7cTWrVvnxNTv8eMkVXK3O+Xl5Tmxyy+/3InV1tZGfs7s7GwnNmLECCemvk/DfoXe3NzsxNT7kMg64yjpZz569+5tEyZMsIqKijbxiooKmzJlSrJ3ByQNuYu4IncRN13StbVo0SK7++677aqrrrJrrrnGnnnmGdu3b5/NmTOnK3YHJA25i7gidxEnXVJ8/PjHP7bDhw/bww8/bAcPHrQxY8bY66+/bsOHD++K3QFJQ+4irshdxEmXXa82d+5cmzt3blc9PdBlyF3EFbmLuEj/i+U9U4Nl9uzZ48SizvMw002o6rpw1bCnmrDM9JCy4uJiJ/bJJ59EWSKSKGrDadTm0p///OcyPnLkSCem8krlwJo1a+Rzjhs3zon9+SyJc9RMBdWsGjaMTzXtDRw40Imp//WvWLEi0vOZmTM3w8zswIEDclt0LzVrQ31GwmbEqCFjKlZXV+fE1Ocm7LtXrUn9GxF14GRcxXeKCQAAiCWKDwAA4BXFBwAA8IriAwAAeEXxAQAAvOJqlyRTV5x8/fXXTkyNTDfTY9fVGOxjx445MXU77LCx3Oo5z54968S2b98uH4+u05krW+6//34npnLSTHfYnzp1yompu2uGjX6urKx0Yj/60Y+cmLrZmboqJuy4VV6qke+ffvqpE6uvr3diYbMwHnnkESf205/+VG6L7nXbbbc5sYKCAicWdg8bdRWMyn2Vp2o7dfVN2H7U7ecHDx7sxCZMmODEtmzZIveT6jjzAQAAvKL4AAAAXlF8AAAAryg+AACAVzScJtnevXud2NixY52Yau4Mi6vRz2rsr2p6Uo19ZroRSz2e8er+RW04HTp0qBMbNmyYE/viiy/kfvr27RtpPU1NTU6ssLBQbvv5559H2n9paakTO3z4sBN7//335X6mTZvmxL788ksnppr+srKynFjYKOuioiIndvfddzuxF154wYmFNXtHbR5GYn72s585MXVrCnUBgJm+Ncbp06ed2JAhQ5yY+o4O+44/ceJEpP2oz9ikSZOcGA2nAAAAEVB8AAAAryg+AACAVxQfAADAKxpOk0w1GW3bts2JqSY+M92kdumllzqx/v37R3rsZ599JvejqMZA1QiFrhXWqNbeiBEjnJh6v9RERTM9JTczM9OJ9ezZM9JjzfSU3ddff92JLVu2zImpps+wtav4V1995cRycnKcWF5enhPr3bu33I+aZnnllVc6MdVwSmOpX6NGjXJiqhlTNRybmfXq1cuJqSZ89d0dlj+KmrCrYup7oLi4OPJ+Uh1nPgAAgFcUHwAAwCuKDwAA4BXFBwAA8IqG0yRTTWb79+93Yjt37oz8nLfffrsTU7dJv/zyy53Yxo0b5XOqRiw1IVI1UqlpfvBPvd9qeqJqIg2jmulUw+mZM2fk41Uzp5oyuX79eiemmmXD9rN7924nphqu1YRS1awadvtzZeLEiZG3RddQt5tX72ttba0TU5NMzfR3t5okrSYLq89dWFO2amxVa1fPqRqg44ozHwAAwCuKDwAA4BXFBwAA8IriAwAAeEXDaZL96U9/cmI/+MEPIm1nphuKVHOqutX4008/7cSqq6vlflQTbF1dnRMLu9U4up+6tbealJhIw6lq0MvOznZiYZNHVYOeaoxVU38LCgqc2IEDB+R+1KRHNV1V3ZZcNcCqNZqZVVVVObEjR444MdWYrV4LJId6X8OmRrenGpPN9Hedauz/4IMPnNiYMWOcmJqua2bW2NjoxNQkVdWArZpQ44ozHwAAwCuKDwAA4BXFBwAA8IriAwAAeEXxAQAAvOJqlyRTVwaoLmw19tlMX3GiqKsN1FUNqovaTHdNq+5qNXY6nUb8xoXq7lf69u3rxPr37y+3VVecnDp1yomp8ephzp4968RUvqg1qStGwq5MUPmvRm6rfav9qCtlwqjP1BVXXOHE1FURSI5Ro0Y5MfX9FfUKGDM9Xl3l1IgRI5zY1q1bndjIkSPlfvbt2+fE1OdO3Vognb57OfMBAAC8ovgAAABeUXwAAACvKD4AAIBXNJwmmWpwUk2oqjHPTI+NVs11qsFJNUxlZWXJ/fTq1cuJqcZC1QgF/0pKSpzYsWPHnJhqOg4b86zyRY04V7miGpHDqAZN1UynPhMDBw6MvB917Oqzoz6PauR12HOqxkb1/tBw2nVGjx7txNR3r8p99f6Z6abuQ4cORVrPe++958TGjh0rt1V5rvJMfT7TaWQ/Zz4AAIBXFB8AAMArig8AAOBVwsXHxo0bbfbs2VZcXGwZGRn2yiuvtPn7IAisvLzciouLLSsry2bMmGE7duxI1nqBDiN3EVfkLtJNwg2nTU1NNnbsWLv33nvttttuc/7+8ccftxUrVthzzz1nI0eOtEceecRmzpxpu3btstzc3KQsOpU1Nzc7MdVgpJoFw6htP/roo0iPDWs4VRNO1fS8dGo4jXPuDhs2zImp9zBsom3U59y7d68TU01uYVNPVVzlr2r6U+sJ2496vMrfqJNQ1efWTOe/ioVNs0yWOOduV1BTRuvr652YmmYb1nCqmv2fe+65SOt59tlnndicOXPktlEnBqt1qkbtuEq4+Jg1a5bNmjVL/l0QBPbEE0/Y0qVL7dZbbzUzs+eff94KCwtt9erVdt9993VutUAnkLuIK3IX6SapPR9VVVVWU1NjZWVlrbHMzEybPn26bdq0ST7m5MmT1tDQ0OYH8K0juWtG/qL7kbuIo6QWHzU1NWbmXi9dWFjY+nftLV++3PLz81t/hg4dmswlAZF0JHfNyF90P3IXcdQlV7u0vxNlEAShd6dcsmSJ1dfXt/5UV1d3xZKASBLJXTPyF6mD3EWcJHXC6bnbxNfU1LRp6qqtrQ29JXhmZqac7hZXqrlUNaip6XVh8ajNqcePH3diquHKTE8DTPcGp2/Tkdw185e/qhlOvTfq1HnY+vLy8pyYyl/VtBmWF6qZTuW0WpN6bNjk0f79+zsx1YCrGq7VazRgwAC5n6NHjzox1dQ7btw4+XgfUj13u4LKXfX9p3JP5bOZnuT7xBNPRFqPmmYbNsVa5Y/67lWN3un0fZzUMx8lJSVWVFRkFRUVrbGWlharrKy0KVOmJHNXQFKRu4grchdxlPCZj2PHjtnu3btb/1xVVWUfffSRFRQU2LBhw2zhwoW2bNkyKy0ttdLSUlu2bJllZ2fbXXfdldSFA4kidxFX5C7STcLFxwcffGDXX399658XLVpkZmb33HOPPffcc7Z48WI7fvy4zZ071+rq6mzy5Mm2fv36tLzWHPFC7iKuyF2km4SLjxkzZoT2K5h90/RUXl5u5eXlnVkXkHTkLuKK3EW64d4uAADAq6Re7QKzQ4cOOTH1P5awMdjq6hTVxa+oq2LCLrVTz/nll186sbCObfjVt29fJ6a64evq6pyYGltuZvbqq69G2o/K37Cx++rqCRVTVxao5wy7MqFPnz5OTOWqyvNPPvnEid10001yP+rY1euu1oOuo3JFXcGn3r/s7Gz5nGomyhdffNGB1X3j8OHDMq6+k9XnVl2BlU55xpkPAADgFcUHAADwiuIDAAB4RfEBAAC8ouE0yQ4ePOjEwkacK6oZSjXnKao5TzVhmekR02q8NVKDatpU46TVmOawpuOdO3c6seuuu86JRR3vb6bHP/fr18+JqQY71RyojsdMNxx+231M/tynn37qxMKaENVznjx50ompY0TXOXLkiBOL+j2pmqrNzN58881Oram9sJv6qcbor7/+2ompWwik03c0Zz4AAIBXFB8AAMArig8AAOAVxQcAAPCKhtMka25ujhQLawRVk08LCgoi7Vs9p2pUNNOTH8Mm8sEv1TismpajNp+FTSM9cOCAE4vatJmVlSXjquE0JyfHialcUw2nYfczidpwql6jzz77zImFNZyqz6N6f9QxhjU2JtLAC62xsdGJqQZN9V5deuml8jn/7u/+LtK+VU6oJtKqqir5+IsuusiJqcnYau1DhgyJssRY4MwHAADwiuIDAAB4RfEBAAC8ovgAAABe0XCaZKrhTjWYqaYlM91kpKbfKaqRLqwxUDUwptPtmuNM3UpbNVOqZkyVP+oW8GHbqpiaMhrWyKwmT6qGazWNUuVqbW2t3I/6nKnXSG2nphCr7cKoybLqvSgqKpKP3717d+R9QVM5rb6/VNNv2HevmvirqCZm1XC6Y8cO+fiSkhInpiZODxw40ImpycBxxZkPAADgFcUHAADwiuIDAAB4RfEBAAC8ouHUA9Vcp6bxmemGv6hNRqphKmwiXl5enhNTjYHwT92eXeWFmlKrHltdXS33o6ZEqkmd6tbgaj1muplPNXOq5kDVcBrWCKqaYNWaVMOhioU1tqpGQrUfddyDBg2Sz0nDaedt27bNiU2aNMmJqcZo1ZhvpvNcUTmhvPbaazK+YMECJ6Y+d4WFhU4snaZQc+YDAAB4RfEBAAC8ovgAAABeUXwAAACvKD4AAIBXXO3iwYUXXujEwjqub7zxRif29NNPR9rPhx9+6MRUB7iZ2f79+52YGhsM/9SobjWi/+TJk05s5MiRTuyTTz6R+1HPqa4iUcJyRV3ZpY5HXamjxpaHjfwPG5HdXkFBgRNrampyYtu3b5ePz83NdWLq6jN1BYS6qgbJ8d///d9O7Kc//akTU1dLqSv9zMxuuOEGJ7Z+/Xonpsb4K7t27ZJx9d2r8kfleNja44gzHwAAwCuKDwAA4BXFBwAA8IriAwAAeEXDqQfTp093YpdeeqncdtasWU7s7rvvjrSfjz/+2Imphjszs/nz5zsxNbJ4y5YtkfaN5FENyqoRVI0jV+PV1ftqZjZw4EAnphoslbDx6mqctWrwVI2AqulOHaOZbng9depUpOccNmyYE/v888/lfqZMmRJpTaqpN52aA1ONyh/1/qum37CmavU9qxpOozZlHzp0SMbV2PThw4c7MbV21agdV5z5AAAAXlF8AAAAryg+AACAVxQfAADAKxpOk0xNv1PNcaWlpfLxu3fvdmJRm4xUI1R+fr7cdvLkyU5MTaeEf+PHj3diqslRxVQzm5rIaWZ21VVXObHm5mYnppo2VcxM53pLS0uk7VQsbJKpmu6qYuozMXbsWCdWX18v9xN16mpOTo4TU6+vmdn//M//yDg6RzVoqs9I2Pdp2DToZFP5oz7zvXv3dmJhDdhxxJkPAADgFcUHAADwiuIDAAB4lVDxsXz5cps4caLl5ubaoEGD7JZbbnHu3BcEgZWXl1txcbFlZWXZjBkzbMeOHUldNJAochdxRe4iHSXUcFpZWWnz5s2ziRMn2unTp23p0qVWVlZmO3fubG24evzxx23FihX23HPP2ciRI+2RRx6xmTNn2q5duyJPT4wzdfvwRBqHVNNcVKphNGwSpWpEDds2HcQpd9VEUNWkdtFFFzkxtc6PPvpI7mfcuHFO7OjRo04sOztbPl5RDddq6qlqLlVTK9VrYaabWFVzqWqMvfjii53YunXr5H7+8z//04mp27mrdR48eFA+Z6LilLvd6fe//70Tu+uuu5zY4cOH5eOPHTuW9DUpe/fudWJqErX6dyOsATuOEvrX5s0332zz51WrVtmgQYNsy5YtNm3aNAuCwJ544glbunSp3XrrrWZm9vzzz1thYaGtXr3a7rvvvuStHEgAuYu4IneRjjpVRp27PO1c1VZVVWU1NTVWVlbWuk1mZqZNnz7dNm3aJJ/j5MmT1tDQ0OYH6GrJyF0z8hf+kbtIBx0uPoIgsEWLFtnUqVNtzJgxZmZWU1NjZu6sgcLCwta/a2/58uWWn5/f+jN06NCOLgmIJFm5a0b+wi9yF+miw8XH/Pnzbdu2bfbiiy86f9f+975BEMjfBZuZLVmyxOrr61t/qqurO7okIJJk5a4Z+Qu/yF2kiw51GC5YsMDWrVtnGzdutCFDhrTGi4qKzOybSnzw4MGt8draWjl50eyb04OqIS2dqOa4sNtthzXYRaEa7lQTn5luTv22/yWli2TmrlnX5O+qVasibacmOl5yySVO7IsvvpCPv+2225yYmoaq9hPW+KYaVgcMGODEVP5FbUw10w3bqtn766+/dmJXX321E3v66aflfgYOHOjEVGOij1udxyF3u9PKlSud2O233+7Ewqbz9uvXz4kl8nmKqrGx0YmppmCV+2HTiuMooTMfQRDY/Pnzbe3atfb2229bSUlJm78vKSmxoqIiq6ioaI21tLRYZWWlTZkyJTkrBjqA3EVckbtIRwmd+Zg3b56tXr3aXn31VcvNzW39n3J+fr5lZWVZRkaGLVy40JYtW2alpaVWWlpqy5Yts+zsbHnJE+ALuYu4IneRjhIqPp566ikzM5sxY0ab+KpVq+wnP/mJmZktXrzYjh8/bnPnzrW6ujqbPHmyrV+//ry51hypidxFXJG7SEcJFR/qd6rtZWRkWHl5uZWXl3d0TUDSkbuIK3IX6Sh9xqUBAIBYSN952ink+PHjTkyNyzbrXNe8uqom7FI7dbXCqVOnOrxv+Keuuti2bZsTCzv1fuGFFzqxI0eOODE1dv+rr76Sz6muQlH7UXmp8jfsf/3qKo2otyZQ4+LHjh0rt33jjTciPSe635dffunE1NVX50bSt6fGmU+aNMmJdfZqF5Wn/fv3j7SedLo6iTMfAADAK4oPAADgFcUHAADwiuIDAAB4RcOpB+fGH/+5sLHRYWOro1ANiGGjhNX+VWMsUoNq0FS5osbpT506VT5n1AZjlRdheTpixAgnVlVVFWk/ahR4WMO0athubm52YmrtqjFx+vTpcj+q4VStKcrlsEieqO/B+vXrnZgauW6mG55vvvlmJ/bSSy9FWWIodQsN9XlSsW+7V0/ccOYDAAB4RfEBAAC8ovgAAABeUXwAAACvaDj1QE2DHDRokNz29OnTHd5PXV2dE1MNiGZ6Ul5tbW2H942upZrpwt7b9kaNGiXj9fX1TkxNVVT7GTlypHzOPXv2ODHVYFdcXOzEVBNpWGOrmqQadWqqiqmm8DDqvaAJ1a+ozdavv/66E7vjjjvkc6rm5CFDhnRgdd8u6udOTRtW04LjijMfAADAK4oPAADgFcUHAADwiuIDAAB4RcOpB6rp6aqrrpLbhk0kjaKxsdGJNTQ0yG1Vc59qFkTqUlNqVdPd8OHD5eNVk9tnn33mxFRO7tq1Sz6napL73ve+F+k5e/Xq5cTCmmpVrkdt5FPN1tnZ2XI/alt1S3QaTv2K+j35+9//3ompCbdmZvn5+U5MNSKPHTvWif3xj3+MtB4z/Z2s8k9dfKAuKogrznwAAACvKD4AAIBXFB8AAMArig8AAOAVxQcAAPCKq108OHHihBNTV5uYRR+ZHZUaQ21mlpOT48TCusCRmqJeTfHggw/K+N///d87sVmzZjmxfv36ObGqqir5nKdOnXJiKge//vprJ9a/f38nlpubK/dTUFDgxAoLC52YugLm0KFDTuzf/u3f5H7UlS1KZ65SQ+I6cyXRvn37ZHz27NlOTF1xMnPmTCeWyNUuKqfDvqfbUzkeV5z5AAAAXlF8AAAAryg+AACAVxQfAADAKxpOPXjhhRec2HXXXSe3feONN5K673Xr1kXedvv27UndN7pW1CbH48ePy/jDDz8c6fHDhg1zYmpkupluiMvLy3NiPXpE+39PS0uLjKtGQNVIqMZrHzt2LNK+kZ5+8YtfyHhNTY0TU/n3zjvvdGr/a9ascWJfffWVEzt69KgTe+uttzq171TCmQ8AAOAVxQcAAPCK4gMAAHiVcj0f6XgbavW7+ebmZrlt2O+4Oyrs9/1KOr72vo8pHV9Dlb+q58JM56+KqVvQK2poWdj+VSzO7we52zXCBjmqYZAqdzs7CFLltNq3ioV97lJNlFzKCFIs4/bv329Dhw7t7mUgTVRXV9uQIUO87Y/8RbKQu4irKLmbcsXH2bNn7cCBA5abm2uNjY02dOhQq66ulh3zcdPQ0MDxeBIEgTU2NlpxcXHkKyuS4Vz+BkFgw4YNS8nXpiNS+b3uiFQ+HnI3uVL5ve6IVD6eRHI35X7t0qNHj9aK6dyp2by8vJR7kTuD4/EjPz/f+z7P5W9DQ4OZpe5r01Ecjx/kbvJxPH5EzV0aTgEAgFcUHwAAwKuULj4yMzPtoYcesszMzO5eSlJwPOePdHttOJ7zR7q9NhxPakq5hlMAAJDeUvrMBwAASD8UHwAAwCuKDwAA4BXFBwAA8Cqli48nn3zSSkpKrE+fPjZhwgR79913u3tJkWzcuNFmz55txcXFlpGRYa+88kqbvw+CwMrLy624uNiysrJsxowZtmPHju5Z7HdYvny5TZw40XJzc23QoEF2yy232K5du9psE6fj8YXc7X7kbseQu6kh3fM3ZYuPNWvW2MKFC23p0qW2detWu+6662zWrFm2b9++7l7ad2pqarKxY8faypUr5d8//vjjtmLFClu5cqVt3rzZioqKbObMmdbY2Oh5pd+tsrLS5s2bZ++9955VVFTY6dOnrayszJqamlq3idPx+EDupgZyN3HkbupI+/wNUtSkSZOCOXPmtImNHj06eOCBB7ppRR1jZsHLL7/c+uezZ88GRUVFwaOPPtoaO3HiRJCfnx/86le/6oYVJqa2tjYws6CysjIIgvgfT1cgd1MTufvdyN3UlW75m5JnPlpaWmzLli1WVlbWJl5WVmabNm3qplUlR1VVldXU1LQ5tszMTJs+fXosjq2+vt7MzAoKCsws/seTbORu6iJ3vx25m9rSLX9Tsvg4dOiQnTlzxgoLC9vECwsLraampptWlRzn1h/HYwuCwBYtWmRTp061MWPGmFm8j6crkLupidz9buRu6krH/E25u9r+uXN3tT0nCAInFldxPLb58+fbtm3b7He/+53zd3E8nq6Uzq9HHI+N3I0unV+PuB5bOuZvSp75GDBggPXs2dOp3mpra50qL26KiorMzGJ3bAsWLLB169bZhg0bbMiQIa3xuB5PVyF3Uw+5Gw25m5rSNX9Tsvjo3bu3TZgwwSoqKtrEKyoqbMqUKd20quQoKSmxoqKiNsfW0tJilZWVKXlsQRDY/Pnzbe3atfb2229bSUlJm7+P2/F0NXI3dZC7iSF3U0va5283NLlG8tJLLwW9evUKnn322WDnzp3BwoULg5ycnGDPnj3dvbTv1NjYGGzdujXYunVrYGbBihUrgq1btwZ79+4NgiAIHn300SA/Pz9Yu3ZtsH379uDOO+8MBg8eHDQ0NHTzyl33339/kJ+fH7zzzjvBwYMHW3+am5tbt4nT8fhA7qYGcjdx5G7qSPf8TdniIwiC4Je//GUwfPjwoHfv3sH48eNbLzFKdRs2bAjMzPm55557giD45hKphx56KCgqKgoyMzODadOmBdu3b+/eRYdQx2FmwapVq1q3idPx+ELudj9yt2PI3dSQ7vmbEQRB0LXnVgAAAP6/lOz5AAAA6YviAwAAeEXxAQAAvKL4AAAAXlF8AAAAryg+AACAVxQfAADAK4oPAADgFcUHAADwiuIDAAB4RfEBAAC8ovgAAABe/T9J3HzSN+TlAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageExamples = iter(val_loader)\n",
    "example_data, example_targets = next(imageExamples)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d2ad6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], train loss: 0.7467, val loss: 0.6232, val_acc: 74.50 %\n",
      "Epoch [4/20], train loss: 0.6938, val loss: 0.5483, val_acc: 79.10 %\n",
      "Epoch [6/20], train loss: 0.5721, val loss: 0.5323, val_acc: 82.03 %\n",
      "Epoch [8/20], train loss: 0.3240, val loss: 0.4838, val_acc: 83.21 %\n",
      "Epoch [10/20], train loss: 0.4893, val loss: 0.4386, val_acc: 83.89 %\n",
      "Epoch [12/20], train loss: 0.3678, val loss: 0.3925, val_acc: 85.35 %\n",
      "Epoch [14/20], train loss: 0.4127, val loss: 0.4398, val_acc: 85.11 %\n",
      "Epoch [16/20], train loss: 0.3358, val loss: 0.4022, val_acc: 86.35 %\n",
      "Epoch [18/20], train loss: 0.1576, val loss: 0.3804, val_acc: 86.13 %\n",
      "Epoch [20/20], train loss: 0.2680, val loss: 0.3626, val_acc: 86.77 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    n_correct_pred = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = lossCriterion(outputs, labels)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for j, (valImages, valLabels) in enumerate(val_loader):\n",
    "            valImages = valImages.to(device)\n",
    "            valLabels = valLabels.to(device)\n",
    "            outputs = model(valImages)\n",
    "            val_loss = lossCriterion(outputs, valLabels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            n_samples += valLabels.size(0)\n",
    "            n_correct_pred += (pred == valLabels).sum().item()\n",
    "    \n",
    "    if (epoch+1) % 2 == 0:\n",
    "        val_acc = (n_correct_pred / n_samples) * 100.0\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {loss.item():.4f}, val loss: {val_loss.item():.4f}, val_acc: {val_acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa90ebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], train loss: 0.6344, val loss: 0.4320, val_acc: 83.73 %\n",
      "Epoch [4/20], train loss: 0.3515, val loss: 0.3662, val_acc: 86.80 %\n",
      "Epoch [6/20], train loss: 0.1531, val loss: 0.3386, val_acc: 87.56 %\n",
      "Epoch [8/20], train loss: 0.2119, val loss: 0.3520, val_acc: 88.71 %\n",
      "Epoch [10/20], train loss: 0.2826, val loss: 0.3452, val_acc: 89.71 %\n",
      "Epoch [12/20], train loss: 0.1403, val loss: 0.3210, val_acc: 89.72 %\n",
      "Epoch [14/20], train loss: 0.2123, val loss: 0.2968, val_acc: 89.75 %\n",
      "Epoch [16/20], train loss: 0.2016, val loss: 0.3117, val_acc: 89.31 %\n",
      "Epoch [18/20], train loss: 0.2072, val loss: 0.3009, val_acc: 89.99 %\n",
      "Epoch [20/20], train loss: 0.2751, val loss: 0.2701, val_acc: 90.04 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    n_correct_pred = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = modern_model(images)\n",
    "        loss = lossCriterion(outputs, labels)\n",
    "        \n",
    "        optim2.zero_grad()\n",
    "        loss.backward()\n",
    "        optim2.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for j, (valImages, valLabels) in enumerate(val_loader):\n",
    "            valImages = valImages.to(device)\n",
    "            valLabels = valLabels.to(device)\n",
    "            outputs = modern_model(valImages)\n",
    "            val_loss = lossCriterion(outputs, valLabels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            n_samples += valLabels.size(0)\n",
    "            n_correct_pred += (pred == valLabels).sum().item()\n",
    "    \n",
    "    if (epoch+1) % 2 == 0:\n",
    "        val_acc = (n_correct_pred / n_samples) * 100.0\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {loss.item():.4f}, val loss: {val_loss.item():.4f}, val_acc: {val_acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0aaa1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], train loss: 0.4459, val loss: 0.4172, val_acc: 85.92 %\n",
      "Epoch [4/20], train loss: 0.3770, val loss: 0.3832, val_acc: 88.04 %\n",
      "Epoch [6/20], train loss: 0.3319, val loss: 0.3707, val_acc: 87.18 %\n",
      "Epoch [8/20], train loss: 0.2495, val loss: 0.3283, val_acc: 89.47 %\n",
      "Epoch [10/20], train loss: 0.1750, val loss: 0.2672, val_acc: 89.77 %\n",
      "Epoch [12/20], train loss: 0.1815, val loss: 0.2296, val_acc: 90.16 %\n",
      "Epoch [14/20], train loss: 0.4033, val loss: 0.2883, val_acc: 89.80 %\n",
      "Epoch [16/20], train loss: 0.2643, val loss: 0.2493, val_acc: 90.89 %\n",
      "Epoch [18/20], train loss: 0.2148, val loss: 0.2303, val_acc: 90.21 %\n",
      "Epoch [20/20], train loss: 0.0624, val loss: 0.2241, val_acc: 91.01 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    n_correct_pred = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = improved_modern_model(images)\n",
    "        loss = lossCriterion(outputs, labels)\n",
    "        \n",
    "        optim3.zero_grad()\n",
    "        loss.backward()\n",
    "        optim3.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for j, (valImages, valLabels) in enumerate(val_loader):\n",
    "            valImages = valImages.to(device)\n",
    "            valLabels = valLabels.to(device)\n",
    "            outputs = improved_modern_model(valImages)\n",
    "            val_loss = lossCriterion(outputs, valLabels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            n_samples += valLabels.size(0)\n",
    "            n_correct_pred += (pred == valLabels).sum().item()\n",
    "    \n",
    "    if (epoch+1) % 2 == 0:\n",
    "        val_acc = (n_correct_pred / n_samples) * 100.0\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {loss.item():.4f}, val loss: {val_loss.item():.4f}, val_acc: {val_acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "16d306af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], train loss: 0.2938, val loss: 0.4115, val_acc: 86.94 %\n",
      "Epoch [4/20], train loss: 0.2651, val loss: 0.3277, val_acc: 88.58 %\n",
      "Epoch [6/20], train loss: 0.2418, val loss: 0.3357, val_acc: 89.67 %\n",
      "Epoch [8/20], train loss: 0.3429, val loss: 0.2624, val_acc: 89.93 %\n",
      "Epoch [10/20], train loss: 0.2177, val loss: 0.3187, val_acc: 90.04 %\n",
      "Epoch [12/20], train loss: 0.2946, val loss: 0.2616, val_acc: 90.67 %\n",
      "Epoch [14/20], train loss: 0.1498, val loss: 0.2822, val_acc: 90.63 %\n",
      "Epoch [16/20], train loss: 0.1333, val loss: 0.2396, val_acc: 91.05 %\n",
      "Epoch [18/20], train loss: 0.1830, val loss: 0.2471, val_acc: 90.98 %\n",
      "Epoch [20/20], train loss: 0.2088, val loss: 0.3217, val_acc: 91.57 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    n_correct_pred = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = improved_modern_model2(images)\n",
    "        loss = lossCriterion(outputs, labels)\n",
    "        \n",
    "        optim4.zero_grad()\n",
    "        loss.backward()\n",
    "        optim4.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for j, (valImages, valLabels) in enumerate(val_loader):\n",
    "            valImages = valImages.to(device)\n",
    "            valLabels = valLabels.to(device)\n",
    "            outputs = improved_modern_model2(valImages)\n",
    "            val_loss = lossCriterion(outputs, valLabels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            n_samples += valLabels.size(0)\n",
    "            n_correct_pred += (pred == valLabels).sum().item()\n",
    "    \n",
    "    if (epoch+1) % 2 == 0:\n",
    "        val_acc = (n_correct_pred / n_samples) * 100.0\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {loss.item():.4f}, val loss: {val_loss.item():.4f}, val_acc: {val_acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f6bcce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], train loss: 0.3330, val loss: 0.4105, val_acc: 84.32 %\n",
      "Epoch [4/20], train loss: 0.4486, val loss: 0.3279, val_acc: 86.39 %\n",
      "Epoch [6/20], train loss: 0.2483, val loss: 0.2779, val_acc: 87.76 %\n",
      "Epoch [8/20], train loss: 0.1477, val loss: 0.3296, val_acc: 89.50 %\n",
      "Epoch [10/20], train loss: 0.2757, val loss: 0.3009, val_acc: 89.73 %\n",
      "Epoch [12/20], train loss: 0.1195, val loss: 0.2890, val_acc: 89.98 %\n",
      "Epoch [14/20], train loss: 0.2284, val loss: 0.2472, val_acc: 89.99 %\n",
      "Epoch [16/20], train loss: 0.1174, val loss: 0.2651, val_acc: 90.25 %\n",
      "Epoch [18/20], train loss: 0.1804, val loss: 0.2754, val_acc: 90.45 %\n",
      "Epoch [20/20], train loss: 0.1136, val loss: 0.2591, val_acc: 90.66 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    n_correct_pred = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = improved_modern_model3(images)\n",
    "        loss = lossCriterion(outputs, labels)\n",
    "        \n",
    "        optim5.zero_grad()\n",
    "        loss.backward()\n",
    "        optim5.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for j, (valImages, valLabels) in enumerate(val_loader):\n",
    "            valImages = valImages.to(device)\n",
    "            valLabels = valLabels.to(device)\n",
    "            outputs = improved_modern_model3(valImages)\n",
    "            val_loss = lossCriterion(outputs, valLabels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            n_samples += valLabels.size(0)\n",
    "            n_correct_pred += (pred == valLabels).sum().item()\n",
    "    \n",
    "    if (epoch+1) % 2 == 0:\n",
    "        val_acc = (n_correct_pred / n_samples) * 100.0\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {loss.item():.4f}, val loss: {val_loss.item():.4f}, val_acc: {val_acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "12464305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], train loss: 0.3079, val loss: 0.3729, val_acc: 87.57 %\n",
      "Epoch [4/20], train loss: 0.4120, val loss: 0.3009, val_acc: 88.75 %\n",
      "Epoch [6/20], train loss: 0.1529, val loss: 0.2737, val_acc: 89.85 %\n",
      "Epoch [8/20], train loss: 0.2285, val loss: 0.2645, val_acc: 90.40 %\n",
      "Epoch [10/20], train loss: 0.1514, val loss: 0.2765, val_acc: 90.47 %\n",
      "Epoch [12/20], train loss: 0.1463, val loss: 0.2840, val_acc: 90.83 %\n",
      "Epoch [14/20], train loss: 0.1003, val loss: 0.3296, val_acc: 91.23 %\n",
      "Epoch [16/20], train loss: 0.0318, val loss: 0.2952, val_acc: 91.69 %\n",
      "Epoch [18/20], train loss: 0.1161, val loss: 0.3612, val_acc: 91.19 %\n",
      "Epoch [20/20], train loss: 0.0464, val loss: 0.4069, val_acc: 91.32 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    n_correct_pred = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = improved_modern_model4(images)\n",
    "        loss = lossCriterion(outputs, labels)\n",
    "        \n",
    "        optim6.zero_grad()\n",
    "        loss.backward()\n",
    "        optim6.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for j, (valImages, valLabels) in enumerate(val_loader):\n",
    "            valImages = valImages.to(device)\n",
    "            valLabels = valLabels.to(device)\n",
    "            outputs = improved_modern_model4(valImages)\n",
    "            val_loss = lossCriterion(outputs, valLabels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            n_samples += valLabels.size(0)\n",
    "            n_correct_pred += (pred == valLabels).sum().item()\n",
    "    \n",
    "    if (epoch+1) % 2 == 0:\n",
    "        val_acc = (n_correct_pred / n_samples) * 100.0\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {loss.item():.4f}, val loss: {val_loss.item():.4f}, val_acc: {val_acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d7288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
